{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Imports\n",
    "from polymer_utils import analysis, general, filetree\n",
    "from polymer_utils import simulation as polysim\n",
    "\n",
    "from polymer_utils import charging\n",
    "from polymer_utils.charging.types import AtomIDMap, ResidueChargeMap\n",
    "from polymer_utils.charging.residues import ChargedResidue\n",
    "\n",
    "from polymer_utils.representation import Polymer, PolymerManager\n",
    "from polymer_utils.representation import LOGGER as polylogger\n",
    "\n",
    "from polymer_utils.molutils import building\n",
    "from polymer_utils.molutils.rdmol import rdcompare, fragment\n",
    "\n",
    "from polymer_utils.solvation.solvents import WATER_TIP3P\n",
    "from polymer_utils.analysis import plotprops, trajectory\n",
    "from polymer_utils.logutils import config_mlf_handler, MultiStreamFileHandler\n",
    "from polymer_utils.graphics import rdkdraw\n",
    "\n",
    "# General Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL.Image import Image # for typing\n",
    "from datetime import datetime\n",
    "from operator import mul, xor\n",
    "\n",
    "# Typing and Subclassing\n",
    "from typing import Any, Callable, ClassVar, Iterable, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "from openmm.unit import Unit, Quantity\n",
    "\n",
    "# File I/O\n",
    "from pathlib import Path\n",
    "import csv, json, pickle\n",
    "from shutil import copyfile, rmtree, move\n",
    "\n",
    "# Logging and Shell\n",
    "from IPython.display import clear_output\n",
    "import subprocess\n",
    "import logging\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "                            \n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolfiles\n",
    "\n",
    "# Molecular Dynamics\n",
    "from openff.units import unit\n",
    "from openff.interchange import Interchange\n",
    "\n",
    "from openff.toolkit import ForceField\n",
    "from openff.toolkit.topology import Topology\n",
    "from openff.toolkit.topology.molecule import Molecule, Atom\n",
    "from openff.toolkit.typing.engines.smirnoff.parameters import LibraryChargeHandler\n",
    "\n",
    "from openmm.openmm import MonteCarloBarostat\n",
    "from openff.toolkit.utils.exceptions import ConformerGenerationError\n",
    "from openff.toolkit.utils.toolkits import RDKitToolkitWrapper, OpenEyeToolkitWrapper, AmberToolsToolkitWrapper\n",
    "\n",
    "from openmm import LangevinMiddleIntegrator, Context\n",
    "from openmm.vec3 import Vec3\n",
    "from openmm.app import Simulation, PDBReporter, StateDataReporter\n",
    "\n",
    "from openmm.unit import picosecond, femtosecond, nanosecond # time\n",
    "from openmm.unit import nanometer, angstrom # length\n",
    "from openmm.unit import kelvin, atmosphere # misc\n",
    "\n",
    "# Static Paths\n",
    "RESOURCE_PATH = Path('resources')\n",
    "COLL_PATH = Path('Collections')\n",
    "COMPAT_PDB_PATH = Path('compatible_pdbs_updated')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Polymer Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset      = False\n",
    "purge_sims = False \n",
    "purge_logs = False\n",
    "\n",
    "# Static Paths\n",
    "RESOURCE_PATH = Path('resources')\n",
    "COLL_PATH = Path('Collections')\n",
    "COMPAT_PDB_PATH = Path('compatible_pdbs_updated')\n",
    "# COMPAT_PDB_PATH = Path('compatible_pdbs')\n",
    "\n",
    "# Paths to structure files\n",
    "poly_source_path = COMPAT_PDB_PATH / 'water_soluble_polymers'\n",
    "# poly_source_path = COMPAT_PDB_PATH / 'simple_polymers_updated'\n",
    "# poly_source_path = COMPAT_PDB_PATH / 'water_soluble_polymers'\n",
    "solv_template    = RESOURCE_PATH/'inp_templates'/'solv_polymer_template_box.inp'\n",
    "desired_solvents = (None,) # (WATER_TIP3P,) # \n",
    "exclusion = 1.0*nanometer\n",
    "\n",
    "# Define derived paths and create manager\n",
    "# collection_path  = COLL_PATH / poly_source_path.name\n",
    "collection_path  = COLL_PATH / f'{poly_source_path.name}_new'\n",
    "structure_path   = poly_source_path / f'{poly_source_path.name}_structures'\n",
    "monomer_path     = poly_source_path / f'{poly_source_path.name}_monomers'\n",
    "\n",
    "mgr = PolymerManager(collection_path)\n",
    "\n",
    "# Perform manager setup / purge actions\n",
    "if purge_logs: # NOTE : must be done BEFORE log FileHandler is created, as this will destroy it's output as well\n",
    "    mgr.purge_logs(really=True)\n",
    "\n",
    "creation_logger = logging.getLogger('polymer_setup')\n",
    "logfile_path = mgr.log_dir/f'Setup_{general.timestamp_now()}.log'\n",
    "\n",
    "with MultiStreamFileHandler(logfile_path, loggers=[creation_logger, polylogger], proc_name=f'Creation of collection \"{mgr.collection_dir.name}\"'):\n",
    "    if reset:\n",
    "        mgr.purge_collection(really=True, purge_logs=False) # Explicitly DON'T purge logs here (will be done prior to entering log loop)\n",
    "\n",
    "    if purge_sims:\n",
    "        mgr.purge_sims(really=True)\n",
    "\n",
    "    if not mgr.polymers: # will be empty if not yet instantiated or if reset prior\n",
    "        mgr.populate_collection(struct_dir=structure_path, monomer_dir=monomer_path)\n",
    "        mgr.solvate_collection(desired_solvents, template_path=solv_template, exclusion=exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trajectory and calculate/plot properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLY_PATH = Path('Collections/simple_polymers_updated')\n",
    "SAMPLE_INTERVAL = 5 # interval between consecutively read time step samples (e.g. 1 would read all steps, 2 every other, etc.)\n",
    "\n",
    "mgr = PolymerManager(POLY_PATH)\n",
    "pdir = mgr.polymers['naturalrubber_solv_water']\n",
    "\n",
    "if not pdir.chrono_sims:\n",
    "    raise ValueError(f'No Simulation results found for {pdir.mol_name}')\n",
    "\n",
    "sim_dir_to_use = pdir.newest_sim_dir\n",
    "print(sim_dir_to_use)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up and load in relevant simulation data from the chosen directory\n",
    "sim_params_path = next(sim_dir_to_use.glob('*_parameters.json'))\n",
    "state_data_path = next(sim_dir_to_use.glob('*_data.csv'))\n",
    "sim_params = SimulationParameters.from_file(sim_params_path)\n",
    "state_data = pd.read_csv(state_data_path)\n",
    "\n",
    "# load simulation frames into an analyzable trajectory\n",
    "traj_path = next(sim_dir_to_use.glob('*_traj.pdb'))\n",
    "traj = trajectory.load_traj(traj_path, topo_path=pdir.structure_file, sample_interval=SAMPLE_INTERVAL, remove_solvent=True)\n",
    "topo = traj.topology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save and plot RDF data\n",
    "rdf_dataframe = trajectory.acquire_rdfs(traj, max_rad=1.0*nanometer)\n",
    "rdf_dataframe.to_csv(sim_dir_to_use/'rdfs.csv')\n",
    "rdf_fig, rdf_ax = plotprops.plot_rdfs(rdf_dataframe, scale=15.0)\n",
    "rdf_fig.suptitle(f'Pairwise Radial Distribution Functions - {pdir.mol_name}')\n",
    "rdf_fig.savefig(sim_dir_to_use/f'RDFs.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# save and plot property data\n",
    "prop_dataframe = trajectory.acquire_time_props(traj, properties=analysis.DEFAULT_PROPS, time_points=sim_params.time_points[::SAMPLE_INTERVAL]) \n",
    "prop_dataframe.to_csv(sim_dir_to_use/'time_series.csv')\n",
    "prop_fig, prop_ax = plotprops.plot_time_props(prop_dataframe, scale=18.0)\n",
    "prop_fig.suptitle(f'Polymer Shape Properties - {pdir.mol_name}')\n",
    "prop_fig.savefig(sim_dir_to_use/f'shape_props.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "filetree.startfile(sim_dir_to_use)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building reduced structures for Colina Polymers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_lim = 180\n",
    "\n",
    "# load source polymers\n",
    "COMPAT_PDB_PATH = Path('compatible_pdbs_updated')\n",
    "poly_source_path = COMPAT_PDB_PATH / 'water_soluble_polymers'\n",
    "collection_path  = COLL_PATH / 'water_soluble_small'\n",
    "\n",
    "structure_path   = poly_source_path / f'{poly_source_path.name}_structures'\n",
    "monomer_path     = poly_source_path / f'{poly_source_path.name}_monomers'\n",
    "\n",
    "mgr = PolymerManager(collection_path)\n",
    "if not mgr.polymers: \n",
    "    mgr.populate_collection(struct_dir=structure_path, monomer_dir=monomer_path) # ensure originals have been loaded\n",
    "\n",
    "# create output dirs\n",
    "reduced_dir = COMPAT_PDB_PATH / 'water_soluble_small'\n",
    "reduced_structures = reduced_dir / f'{reduced_dir.name}_structures'\n",
    "reduced_monomers   = reduced_dir / f'{reduced_dir.name}_monomers'\n",
    "\n",
    "reduced_dir.mkdir(       exist_ok=True)\n",
    "reduced_monomers.mkdir(  exist_ok=True)\n",
    "reduced_structures.mkdir(exist_ok=True)\n",
    "\n",
    "# generate new structures\n",
    "reverse = False # needed\n",
    "for pdir in mgr.polymers_list:\n",
    "    print(pdir.mol_name)\n",
    "    monomers = pdir.monomer_data['monomers']\n",
    "    if pdir.mol_name == 'paam_modified':\n",
    "        monomers.pop('paam_SPECIAL_TERM')\n",
    "        reverse = True\n",
    "\n",
    "    chain = building.build_linear_polymer_limited(monomers, max_chain_len=chain_lim, reverse_term_labels=reverse)\n",
    "    chain.save(str(reduced_structures/f'{pdir.mol_name}.pdb'), overwrite=True)\n",
    "    copyfile(pdir.monomer_file, reduced_monomers/f'{pdir.mol_name}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing pdb structure and json monomer files and taking inventories of files present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import move\n",
    "\n",
    "PARENT = Path('compatible_pdbs_updated')\n",
    "JSON_SRC = PARENT / 'json_files'\n",
    "\n",
    "def organize_struct_mono_files(dump_dir : Path, mono_src : Path):\n",
    "    '''For organizing structure and monomer files in a dump directory '''\n",
    "    for dir in dump_dir.iterdir():\n",
    "        if dir.is_dir() and (dir != mono_src): # to encompass the possibility that the json dir is in fact inside the dump folder\n",
    "            struct_dir = dir/f'{dir.name}_structures'\n",
    "            mono_dir = dir/f'{dir.name}_monomers'\n",
    "\n",
    "            struct_dir.mkdir(exist_ok=True)\n",
    "            mono_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            data_rows = []\n",
    "            for pdb in dir.glob('*.pdb'):\n",
    "                json_path = mono_src/f'{pdb.stem}.json'\n",
    "                row_dict = {\n",
    "                    'Species' : pdb.stem,\n",
    "                    'PDB present' : True,\n",
    "                    'JSON present' : json_path.exists()\n",
    "                }\n",
    "\n",
    "                move(pdb, struct_dir)\n",
    "                if row_dict['JSON present']:\n",
    "                    move(json_path, mono_dir)\n",
    "                data_rows.append(row_dict)\n",
    "            \n",
    "            inventory = pd.DataFrame(data_rows)\n",
    "            inventory.to_csv(dir/f'{dir.name}_inventory.csv')\n",
    "\n",
    "organize_struct_mono_files(PARENT, JSON_SRC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Polymer building and from-monomer calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "mol_name = 'peg_modified' \n",
    "# mol_name = 'pnipam_modified' \n",
    "# mol_name = 'paam_modified'\n",
    "\n",
    "pdir = mgr.polymers[mol_name]\n",
    "offmol = pdir.offmol_matched(strict=False, verbose=False)\n",
    "rdmol = offmol.to_rdkit()\n",
    "\n",
    "# Labelled all unmatched atoms\n",
    "for i, atom in enumerate(offmol.atoms):\n",
    "    rdatom = rdmol.GetAtomWithIdx(i)\n",
    "    rdatom.SetProp('atomNote', atom.metadata.get('residue_name', 'unmatched'))\n",
    "print('Matched residues : ', set(atom.metadata.get('residue_name') for atom in offmol.atoms))\n",
    "\n",
    "# Bounding monomer sizes \n",
    "max_mono_size = max(Chem.MolFromSmarts(SMARTS).GetNumAtoms() for SMARTS in pdir.monomer_data['monomers'].values())\n",
    "print(max_mono_size)\n",
    "\n",
    "# confirming order match with OpenFF\n",
    "for atom in rdmol.GetAtoms():\n",
    "    if atom.GetSymbol() != offmol.atoms[atom.GetIdx()].symbol:\n",
    "        print(f'{atom} mismatched')\n",
    "else:\n",
    "    print('IDs match with offmol!')\n",
    "\n",
    "rdkdraw.set_rdkdraw_size(800, 1/1)\n",
    "rdmol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show monomers\n",
    "rdkdraw.set_rdkdraw_size(300, 2/1)\n",
    "for mono_name, mono_SMARTS in pdir.monomer_data['monomers'].items():\n",
    "    monomer = Chem.MolFromSmarts(mono_SMARTS) \n",
    "    print(mono_name, monomer.GetNumAtoms(), mono_SMARTS, monomer.GetNumAtoms())\n",
    "    display(monomer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdir in mgr.polymers_list:\n",
    "    if pdir.has_monomer_data:\n",
    "        mono = pdir.monomer_data['monomers']\n",
    "        print(pdir.mol_name, building.count_middle_and_term_mono(mono), '\\n\\tLinear : ', building.is_linear_polymer(mono), '\\n\\tHomo : ', building.is_homopolymer(mono))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "solvent = None\n",
    "DOP_min, DOP_max = 3, 10\n",
    "\n",
    "# testing that chain length errors (if any) are independent of DOP\n",
    "res = []\n",
    "logs = defaultdict(list)\n",
    "for i, polymer in enumerate(mgr.polymers_list):\n",
    "    if polymer.solvent == solvent:\n",
    "        print(polymer.mol_name)\n",
    "        try:\n",
    "            mono_structs = polymer.monomer_data['monomers']\n",
    "            if polymer.mol_name == 'paam_modified':\n",
    "                mono_structs.pop('paam_SPECIAL_TERM')\n",
    "\n",
    "            print(f'{len(mono_structs)} monomers in chain')\n",
    "\n",
    "            dop_errors = []\n",
    "            for DOP in range(DOP_min, DOP_max):\n",
    "                n_atoms_pred = building.estimate_chain_len(mono_structs, DOP=DOP)\n",
    "                chain = building.build_linear_polymer(mono_structs, DOP=DOP, add_Hs=False)\n",
    "                n_atoms_real = chain.n_particles\n",
    "                print(n_atoms_real, n_atoms_pred)\n",
    "                dop_errors.append(n_atoms_real - n_atoms_pred)\n",
    "            res.append(dop_errors)\n",
    "            logs['Success'].append(polymer.mol_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logs[type(e).__name__].append(polymer.mol_name)\n",
    "\n",
    "res = np.array(res)            \n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing heatmapping drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('turbo')\n",
    "# pdir = mgr.polymers['polythiophene_solv_water']\n",
    "pdir = mgr.polymers['polyethylmethacrylate_solv_water']\n",
    "\n",
    "dim = 10\n",
    "aspect = 4/1\n",
    "annotate = False\n",
    "\n",
    "for cvtr_type in ('InChI', 'SMARTS', 'CXSMARTS'):\n",
    "    fig, ax = pdir.compare_charges('ABE10_exact', 'Espaloma_AM1BCC', cmap, annotate=annotate, precision=5, converter=cvtr_type)\n",
    "    fig.set_size_inches(dim, dim * aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "\n",
    "\n",
    "cvtr = 'InChI'\n",
    "\n",
    "offmol1 = pdir.charged_offmol_from_sdf('ABE10_exact')\n",
    "rdmol1 = offmol1.to_rdkit()\n",
    "flatmol1 = rdcompare.flattened_rdmol(rdmol1, converter=cvtr)\n",
    "\n",
    "offmol2 = pdir.charged_offmol_from_sdf('Espaloma_AM1BCC')\n",
    "rdmol2 = offmol2.to_rdkit()\n",
    "flatmol2 = rdcompare.flattened_rdmol(rdmol2, converter=cvtr)\n",
    "\n",
    "diff = rdcompare.difference_rdmol(flatmol1, flatmol2, prop='PartialCharge', remove_map_nums=True)\n",
    "deltas = [diff.GetAtomWithIdx(i).GetDoubleProp('DeltaPartialCharge') for i in range(diff.GetNumAtoms())]\n",
    "fig = SimilarityMaps.GetSimilarityMapFromWeights(diff, deltas, colorMap='jet', contourLines=10, alpha=0.3)\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.frombytes('RGBA', fig.canvas.get_width_height(), fig.canvas.tostring_argb())\n",
    "\n",
    "n = 250\n",
    "img = PIL.Image.frombytes('RGB', (n, n), fig.canvas.tostring_rgb())\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdir = mgr.polymers['polyvinylchloride_solv_water']\n",
    "\n",
    "fig1, ax1 = pdir.compare_charges('ABE10_exact', 'Espaloma_AM1BCC', cmap=plt.get_cmap('turbo'), converter='InChI')\n",
    "fig2, ax2 = pdir.compare_charges('ABE10_exact', 'Espaloma_AM1BCC', cmap=plt.get_cmap('turbo'), converter='SMARTS')\n",
    "\n",
    "ax1.set_title(pdir.mol_name)\n",
    "ax2.set_title(pdir.mol_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating heatmaps for all completed simulation in the Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_methods = ('ABE10_exact', 'Espaloma_AM1BCC')\n",
    "outdir = Path('pcharge_heatmaps')/mgr.collection_dir.name\n",
    "outdir.mkdir(exist_ok=True)\n",
    "cmaps = [\n",
    "    'seismic',\n",
    "    'turbo',\n",
    "    # 'rainbow',\n",
    "    # 'terrain',\n",
    "    # 'BrBG',\n",
    "    # 'cool',\n",
    "    # 'spring',\n",
    "    # 'plasma'\n",
    "]\n",
    "\n",
    "for mol_name in mgr.all_completed_sims:\n",
    "    polymer = mgr.polymers[mol_name]\n",
    "    charged_mols = {\n",
    "        chg_method : polymer.charged_offmol_from_sdf(chg_method).to_rdkit()\n",
    "            for chg_method in charge_methods\n",
    "    }\n",
    "    charged_mols.values()\n",
    "\n",
    "    for cmap_name in cmaps:\n",
    "        cmap_dir = outdir/cmap_name\n",
    "        cmap_dir.mkdir(exist_ok=True)\n",
    "        cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "        fig, ax = rdkdraw.compare_chgd_rdmols(*charged_mols.values(), *charged_mols.keys(), cmap=cmap, flatten=True)\n",
    "        fig.savefig(cmap_dir/f'{mol_name}.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probing updated monomers (from future - difference was numbered ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "mp_prior = SIMPLE_POLY_PATH / 'simple_polymers_monomers_prior'\n",
    "mp_updated = SIMPLE_POLY_PATH / 'simple_polymers_monomers_updated'\n",
    "\n",
    "monomers = defaultdict(dict)\n",
    "pairs = (\n",
    "    ('prior', mp_prior), \n",
    "    ('updated', mp_updated)\n",
    ")\n",
    "\n",
    "for (label, src_dir) in pairs:\n",
    "    for path in src_dir.glob('**/*.json'):\n",
    "        with path.open('r') as mp_file:\n",
    "            monomers[label][path.stem] = json.load(mp_file)\n",
    "\n",
    "all_species = set(monomers['prior'].keys()) | set(monomers['updated'].keys())\n",
    "for species in all_species:\n",
    "    if (spec_prior := monomers['prior'].get(species)) and (spec_updated := monomers['updated'].get(species)):\n",
    "        if spec_prior['monomers'] != spec_updated['monomers']:\n",
    "            print(species, '\\n\\t', spec_prior['monomers'], '\\n\\t', spec_updated['monomers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_mol = 'naturalrubber'\n",
    "\n",
    "priors = [Chem.MolFromSmarts(SMARTS) for SMARTS in monomers['prior'][targ_mol]['monomers'].values()]\n",
    "currs  = [Chem.MolFromSmarts(SMARTS) for SMARTS in monomers['updated'][targ_mol]['monomers'].values()]\n",
    "\n",
    "for prior_rdmol, new_rdmol in zip(priors, currs):\n",
    "    display(prior_rdmol)\n",
    "    display(new_rdmol)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge/Sim loop V1 proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE TARGET MOLECULES AND FORCEFIELD\n",
    "# sample_mols = mols_to_use[:3]\n",
    "sample_mols = ['polyvinylchloride']\n",
    "main_ff_xml = CORE_PATH/'force_fields'/'openff_unconstrained-2.0.0.offxml'\n",
    "\n",
    "# CHARGING PARAMETERS\n",
    "toolkit = 'OpenEye Toolkit'\n",
    "partial_charge_method = 'am1bccelf10'\n",
    "\n",
    "# CHARGING / SIM LOOP BEHAVIOR\n",
    "overwrite_ff_xml   = True\n",
    "overwrite_chg_json = True\n",
    "distrib_mono_charges = True\n",
    "run_sims = True\n",
    "strict = True\n",
    "verbose = False\n",
    "\n",
    "# SIMULATION PARAMETERS \n",
    "temperature = 300 * kelvin\n",
    "friction_coeff = 1/picosecond\n",
    "\n",
    "sim_time = 0.001 * nanosecond #5 * nanosecond \n",
    "timestep = 1 * femtosecond\n",
    "num_samples = 100 #2_000\n",
    "\n",
    "# AUXILIARY PRE-FLIGHT CALCULATIONS\n",
    "sample_dirs = {\n",
    "    mol_name : mgr.polymers.get(mol_name)\n",
    "        for mol_name in sample_mols\n",
    "}\n",
    "action_str = f'Charging{\" & simulation\" if run_sims else \"\"}'\n",
    "\n",
    "num_steps   = round(sim_time / timestep)\n",
    "record_freq = round(num_steps / num_samples)\n",
    "num_mols = len(sample_dirs)\n",
    "print(num_steps, record_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_logger = logging.getLogger(charging.__name__)\n",
    "\n",
    "def create_pickled_cmol(polymer : Polymer, toolkit : str, partial_charge_method : str, strict : bool=True, verbose : bool=False) -> None:\n",
    "    '''Ensure that a pickled, charged molecule exists for the mol directory - perform charging with method of choice if none exists'''\n",
    "    pickle_path = polymer.pkl/f'{polymer.mol_name}.pkl'\n",
    "\n",
    "    chg_logger.info(f'Loading topology and molecule via graph match...')\n",
    "    mol = polymer.largest_offmol_matched(strict=strict, verbose=verbose, topo_only=True)\n",
    "    chg_logger.info(f'Charging {polymer.mol_name} via {toolkit}-{partial_charge_method}...')\n",
    "    cmol = charging.charging.generate_molecule_charges(mol, toolkit=toolkit, partial_charge_method=partial_charge_method) \n",
    "\n",
    "    with pickle_path.open('wb') as pickle_file: # write charged molecule to pickle to avoid constantly redoing AM1\n",
    "        pickle.dump(cmol, pickle_file)\n",
    "\n",
    "    polymer.info.pickle_file = pickle_path # ensure change is reflected in directory info\n",
    "    polymer.to_file() # record all changes to disc\n",
    "\n",
    "def create_chg_avg_mono(polymer : Polymer, distrib_mono_charges : bool=True) -> tuple[list[ChargedResidue], AtomIDMap]:\n",
    "    '''Create a charge-averaged monomer file from an existing monomer spec file and a charged OFF Molecule'''\n",
    "    chg_logger.info('Unpickling charged Molecule for charge averaging...')\n",
    "    with polymer.info.pickle_file.open('rb') as pickle_file: \n",
    "        cmol = pickle.load(pickle_file) # load AM1-charged molecule from file (must exist by this point in loop)\n",
    "\n",
    "    chg_logger.info(f'Averaging charges over {polymer.mol_name} residues...')\n",
    "    avgs, atom_id_mapping = charging.averaging.get_averaged_charges(cmol, monomer_data=polymer.monomer_data, distrib_mono_charges=distrib_mono_charges) # average charges over unique residues\n",
    "    mono_chgs = {avgd_res.residue_name : avgd_res.charges for avgd_res in avgs}\n",
    "    \n",
    "    chg_logger.info(f'Writing new charged JSON monomer file...')\n",
    "    polymer.create_charged_monomer_file(mono_chgs)\n",
    "\n",
    "    return avgs, atom_id_mapping\n",
    "\n",
    "def create_off_xml(polymer : Polymer, xml_src : Path) -> tuple[ForceField, list[LibraryChargeHandler]]:\n",
    "    '''Generate an OFF force field with molecule-specific (and solvent specific, if applicable) Library Charges appended'''\n",
    "    ff_path = polymer.FF/f'{polymer.mol_name}.offxml' # path to output library charges to\n",
    "    chg_logger.info('Writing new force field OFFXML file')\n",
    "    forcefield, lib_chgs = charging.averaging.write_lib_chgs_from_mono_data(polymer.monomer_data_charged, xml_src, output_path=ff_path)\n",
    "\n",
    "    if polymer.info.solvent is not None:\n",
    "        chg_logger.info('Associated solvent found, merging Library-Charged force field with solvent force field...')\n",
    "        forcefield = ForceField(ff_path, polymer.info.solvent.forcefield_file, allow_cosmetic_attributes=True) # use both the polymer-specific xml and the solvent FF xml to make hybrid forcefield\n",
    "        forcefield.to_file(ff_path)\n",
    "\n",
    "    polymer.info.ff_file = ff_path # ensure change is reflected in directory info\n",
    "    polymer.to_file() # record all changes to disc\n",
    "\n",
    "    return forcefield, lib_chgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN CHARGING / SIM LOOP - Perform charge averaging on all target molecules which don't already have averaged LCs; Load forcefield for those which already do \n",
    "main_logger = logging.getLogger(__name__)\n",
    "loggers = [main_logger, chg_logger]\n",
    "main_log_handler = config_mlf_handler(mgr.log_dir/f'Polymer_battery_{general.timestamp_now()}.log', loggers, writemode='a')\n",
    "\n",
    "main_logger.info(f'Beginning {action_str} loop...\\n')\n",
    "for i, (mol_name, polymer) in enumerate(sample_dirs.items()):\n",
    "    # 0) LOAD MOLECULE AND TOPOLOGY, ATTEMPT TO APPLY LIBRARY CHARGES\n",
    "    start_time = datetime.now()\n",
    "    main_logger.info(f'Current molecule: \"{mol_name}\" ({i + 1}/{num_mols})') # +1 converts to more human-readable 1-index for step count\n",
    "    polymer_log_handler = config_mlf_handler(polymer.logs/f'{general.timestamp_now()}.log', loggers, writemode='w') # NOTE : order matters, initial main logger call above should not record to local polymer log\n",
    "    if not polymer.has_monomer_data:\n",
    "        raise FileExistsError(f'No monomer JSONs found for {mol_name}')\n",
    "    \n",
    "    # 1) ENSURING AN AM1-BCC-ELF10-CHARGED MOLECULE EXISTS (IN PICKLE FORM). WILL RECHARGE IF NONE EXISTS\n",
    "    if (polymer.info.pickle_file is None):\n",
    "        main_logger.warning('(1-precheck) Generating new pickled charged OpenFF Molecule...')\n",
    "        try:\n",
    "            create_pickled_cmol(polymer, toolkit, partial_charge_method, strict, verbose)\n",
    "        except ConformerGenerationError:\n",
    "            main_logger.error('Could not successfully generate conformers\\n')\n",
    "            continue \n",
    "    main_logger.info('(1) Found pickled charged molecule...')\n",
    "    \n",
    "    # 2) CREATE JSON WITH AVERAGED CHARGES IF ONE DOES NOT ALREADY EXIST\n",
    "    if (polymer.info.monomer_file_chgd is None) or overwrite_chg_json: # can only reach this branch if a json is present but isn't identified as charged within the Polymer\n",
    "        main_logger.warning('(2-precheck) Generating new charged monomer JSON...')\n",
    "        create_chg_avg_mono(polymer, distrib_mono_charges=distrib_mono_charges)\n",
    "    main_logger.info('(2) Found charged monomer JSON...')\n",
    "\n",
    "    # 3) CREATE FORCE FIELD XML WITH MONOMER-BASED LIBRARY CHARGE ENTRIES\n",
    "    if (polymer.info.ff_file is None) or overwrite_ff_xml: # can only reach if a charged monomer json already exists\n",
    "        main_logger.warning('(3-precheck) Generating new Force Field XML with Library Charges...')\n",
    "        create_off_xml(polymer, xml_src=main_ff_xml)\n",
    "    main_logger.info('(3) Found Force Field file with Library Charges...')\n",
    "\n",
    "    # 4) RUN OpenMM SIMULATION FOR TARGET MOLECULE\n",
    "    if run_sims:\n",
    "        main_logger.info('(4) Preparing simulation...')\n",
    "        output_folder = polymer.make_res_dir()\n",
    "        sim_log_handler = config_mlf_handler(output_folder/f'{polymer.mol_name} simulation.log', loggers)\n",
    "\n",
    "        main_logger.info('Loading Topology...')\n",
    "        openff_topology = polymer.openff_topology_matched(strict=strict, verbose=verbose, topo_only=True)\n",
    "        openff_topology.box_vectors = polymer.box_vectors.in_units_of(nanometer) # set box vector to allow for periodic simulation (will be non-periodic if polymer box vectors are unset i.e. NoneType)\n",
    "\n",
    "        main_logger.info('Loading charged Molecule...')\n",
    "        with polymer.info.pickle_file.open('rb') as pickle_file: \n",
    "            cmol = pickle.load(pickle_file) # load AM1-charged molecule from file (must exist by this point in loop)\n",
    "\n",
    "        main_logger.info('Loading Force Field...')\n",
    "        forcefield = ForceField(polymer.info.ff_file, allow_cosmetic_attributes=True)\n",
    "\n",
    "        main_logger.info('Creating Simulation from Interchange...')\n",
    "        interchange = Interchange.from_smirnoff(force_field=forcefield, topology=openff_topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "        integrator  = LangevinMiddleIntegrator(temperature, friction_coeff, timestep)\n",
    "        sim = polysim.create_simulation(interchange, integrator)\n",
    "        \n",
    "        main_logger.info(f'Running {sim_time} OpenMM sim at {temperature} for {num_steps} steps...')\n",
    "        polysim.run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=num_steps, record_freq=record_freq)\n",
    "\n",
    "        polymer.to_file() # ensure directory data reflects changes to files\n",
    "        # filetree.startfile(output_folder)\n",
    "        sim_log_handler.remove_from_loggers(*loggers)  \n",
    "    \n",
    "    proc_time = str(datetime.now() - start_time)\n",
    "    main_logger.info(f'Successfully completed actions on {mol_name} in {proc_time}\\n')\n",
    "    clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "    polymer_log_handler.remove_from_loggers(*loggers)  \n",
    "\n",
    "main_logger.info(f'{action_str} loop completed')\n",
    "main_log_handler.remove_from_loggers(*loggers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Sims v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymers = mgr.polymers\n",
    "\n",
    "desired_solvents = (WATER_TIP3P,) #,None)\n",
    "hard_polymers = ['vulcanizedrubber', 'polyphenylenesulfone', 'polyethylene'] # pathological or otherwise difficult-to-run polymers that I've encountered\n",
    "hard_polymers_solv = [\n",
    "    f'{unsolv_mol}_solv_{solvent.name}'\n",
    "        for solvent in desired_solvents\n",
    "            for unsolv_mol in hard_polymers\n",
    "]\n",
    "hard_polymers.extend(hard_polymers_solv) # ensure solvated names are also included\n",
    "\n",
    "mols_to_use = [polymer.mol_name\n",
    "    for polymer in polymers.values()\n",
    "        if (polymer.mol_name not in hard_polymers)         # 1) are not manually excluded\n",
    "            and (0 < polymer.n_atoms <= 300)               # 2) are loadable (i.e. non-zero size) but are small enough for AM1BCC (150 is speed limit, 300 is error limit)\n",
    "            and (polymer.has_monomer_data)                 # 3) have monomer information files\n",
    "            and (polymer.info.solvent in desired_solvents) # 4) is solvated in the specified solvents (could be None)\n",
    "]\n",
    "\n",
    "print(mols_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE TARGET MOLECULES AND FORCEFIELD\n",
    "sample_mols = mols_to_use\n",
    "# sample_mols = ['polyvinylchloride_solv_water']\n",
    "main_ff_xml = CORE_PATH/'force_fields'/'openff_unconstrained-2.0.0.offxml'\n",
    "solv_ff_xml = CORE_PATH/'force_fields'/'tip3p.offxml'\n",
    "\n",
    "# SET CHARGING LOOP BEHAVIOR\n",
    "prevent_overwrites = False # to deprecate\n",
    "distrib_mono_charges = True\n",
    "run_sims = True\n",
    "verbose = False\n",
    "\n",
    "# SIMULATION PARAMETERS \n",
    "temperature = 300 * kelvin\n",
    "friction_coeff = 1/picosecond\n",
    "\n",
    "sim_time = 5 * nanosecond \n",
    "timestep = 1 * femtosecond\n",
    "num_samples = 2_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-FLIGHT CHECKS\n",
    "sample_dirs = {\n",
    "    mol_name : polymers.get(mol_name)\n",
    "        for mol_name in sample_mols\n",
    "}\n",
    "\n",
    "num_steps   = round(sim_time / timestep)\n",
    "record_freq = round(num_steps / num_samples)\n",
    "num_mols = len(sample_dirs)\n",
    "print(num_steps, record_freq)\n",
    "\n",
    "main_log_dir = POLY_PATH/'Logs'\n",
    "main_log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "master_logger = setup_logger(f'Polymer_battery_{general.timestamp_now()}', outpath=main_log_dir, formatter=LOG_FORMATTER, writemode='w')\n",
    "master_handler = master_logger.handlers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN CHARGING / SIM LOOP - Perform charge averaging on all target molecules which don't already have averaged LCs; Load forcefield for those which already do \n",
    "for i, (mol_name, polymer) in enumerate(sample_dirs.items()):\n",
    "    log_name = mol_name #f'{mol_name}_chg_sim_log' #{general.timestamp_now()}'\n",
    "    logger = setup_logger(log_name, outpath=polymer.logs, writemode='a', formatter=LOG_FORMATTER)\n",
    "    logger.addHandler(master_handler) # ensure output is also logged to the master\n",
    "\n",
    "    # DEFINING PATHS, CREATING FOLDERS, AND FETCHING FILES\n",
    "    pdb_path      = polymer.info.structure_file\n",
    "    lc_path       = polymer.FF/f'new {mol_name} charges.offxml' # path to output library charges to\n",
    "    pickle_path   = polymer.pkl/f'{mol_name}.pkl'\n",
    "    output_folder = polymer.make_res_dir()\n",
    "\n",
    "    # LOAD MOLECULE AND TOPOLOGY, ATTEMPT TO APPLY LIBRARY CHARGES\n",
    "    logger.info(f'Current molecule: {mol_name} ({i + 1}/{num_mols})') # +1 converts to more human-readable 1-index for step count\n",
    "    json_path = polymer.monomer_file_ranked\n",
    "    if json_path is None:\n",
    "        raise FileExistsError(f'No monomer JSONs found for {mol_name}')\n",
    "    \n",
    "    logger.info(f'Using monomer file \"{json_path}\"...')\n",
    "    with json_path.open('r') as json_file:\n",
    "        mono_data = json.load(json_file)\n",
    "\n",
    "    logger.info(f'Loading and matching molecule \"{mol_name}\"...')\n",
    "    openff_topology, _, _error = Topology.from_pdb_and_monomer_info(str(pdb_path), json_path, strict=True, verbose=verbose)\n",
    "    openff_topology.box_vectors = polymer.box_vectors.in_units_of(nanometer) # set box vector to allow for periodic simulation (will be non-periodic if polymer box vectors are unset i.e. NoneType)\n",
    "    mol = next(openff_topology.molecules) # get the first molecule (assumed to be the polymer of interest)\n",
    "\n",
    "    if prevent_overwrites and lc_path.exists(): # check if library charges have already been generated for this molecule\n",
    "        logger.info('Obtaining partial charges from Library Charge xml...')\n",
    "        forcefield = ForceField(lc_path, solv_ff_xml, allow_cosmetic_attributes=True) # use both the polymer-specific xml and the solvent FF xml when creating the Forcefield\n",
    "        \n",
    "        logger.info('Unpickling charged Molecule...')\n",
    "        with pickle_path.open('rb') as pickle_file: # read cmol from file if already extant\n",
    "            cmol = pickle.load(pickle_file)\n",
    "    else:\n",
    "        # PERFORMING INITIAL AM1-BCC CHARGING, OR UNPICKLING MOLECULE IF THIS HAS ALREADY BEEN DONE\n",
    "        if not pickle_path.exists():\n",
    "            logger.warning('No extant pickled charged Molecule found, performing charging...')\n",
    "            try:\n",
    "                cmol = polychg.generate_molecule_charges(mol, partial_charge_method='am1bccelf10') # perform AM1BCC\n",
    "            except ConformerGenerationError:\n",
    "                logger.warning('Could not successfully generate conformers')\n",
    "                continue \n",
    "\n",
    "            with pickle_path.open('wb') as pickle_file: # write charged molecule to pickle to avoid constantly redoing AM1\n",
    "                pickle.dump(cmol, pickle_file)\n",
    "            polymer.info.pickle_file = pickle_path\n",
    "        \n",
    "        logger.info('Unpickling charged Molecule...')\n",
    "        with pickle_path.open('rb') as pickle_file: # read cmol from file if already extant\n",
    "            cmol = pickle.load(pickle_file)\n",
    "\n",
    "        # CHARGE AVERAGING\n",
    "        logger.info(f'Averaging charges over {mol_name} residues...')\n",
    "        avgs, atom_id_mapping = polychg.get_averaged_charges(cmol, monomer_data=mono_data, distrib_mono_charges=distrib_mono_charges) # average charges over unique residues\n",
    "\n",
    "        logger.warning('Library Charge file not found OR overwrite allowed, writing new Library Charge xml...')\n",
    "        forcefield, lib_chgs = polychg.write_new_library_charges(avgs, main_ff_xml, output_path=lc_path)\n",
    "        polymer.info.ff_file = lc_path\n",
    "        \n",
    "        # CREATE JSON WITH AVERAGED CHARGES IF ONE DOES NOT ALREADY EXIST\n",
    "        if polymer.info.monomer_file_chgd is None:\n",
    "            logger.info('Writing new monomer JSON with charge data...')\n",
    "\n",
    "            mono_chgs = {avgd_res.residue_name : avgd_res.charges for avgd_res in avgs}\n",
    "            if polymer.info.solvent is not None:\n",
    "                mono_data['charges'] = {**mono_chgs, **polymer.info.solvent.monomer_json_data['charges']} # ensure solvent \"monomer\" charges are also recorded\n",
    "\n",
    "            chgd_json_path = json_path.with_name(f'{json_path.stem}_charged.json')\n",
    "            chgd_json_path.touch()\n",
    "            with chgd_json_path.open('w') as new_json:\n",
    "                json.dump(mono_data, new_json, indent=4)\n",
    "            polymer.info.monomer_file_chgd = chgd_json_path\n",
    "\n",
    "    # RUN OpenMM SIMULATION FOR TARGET MOLECULE\n",
    "    if run_sims:\n",
    "        logger.info(f'Running {sim_time} OpenMM sim at {temperature} for {num_steps} steps...')\n",
    "\n",
    "        forcefield = ForceField(lc_path, solv_ff_xml, allow_cosmetic_attributes=True)\n",
    "        interchange = Interchange.from_smirnoff(force_field=forcefield, topology=openff_topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "        integrator  = LangevinMiddleIntegrator(temperature, friction_coeff, timestep)\n",
    "        \n",
    "        sim = polysim.create_simulation(interchange, integrator)\n",
    "        polysim.run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=num_steps, record_freq=record_freq)\n",
    "    \n",
    "    polymer.to_file() # ensure directory data reflects changes to files\n",
    "    # filetree.startfile(output_folder)\n",
    "    clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "    logger.info(f'Successfully completed actions on {mol_name}\\n')\n",
    "    logger.removeHandler(master_handler) # free up master log handler - prevents bleed-over between multiple sim sessions\n",
    "\n",
    "master_logger.info(f'Charging{\" & simulation\" if run_sims else \"\"} loop completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_sims = lambda : set(sample_mols) - set(mgr.all_completed_sims(polymers).keys())\n",
    "failed_sims()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating monomer files for polyamides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLYAM_PATH   = Path('compatible_pdbs/polyamides')\n",
    "p = POLYAM_PATH/'smiles.json'\n",
    "\n",
    "with p.open('r') as smiles_file:\n",
    "    mono_smiles = json.load(smiles_file)\n",
    "mono_smiles['TMC'] = mono_smiles['TMC'].replace('Cl', 'O[H]') # replace chlorides with oxygens present in full polymer\n",
    "\n",
    "rdkdraw.set_rddraw_size(400, 3/2)\n",
    "\n",
    "mono_mols, mono_smarts = {}, {}\n",
    "for name, SMILES in mono_smiles.items():\n",
    "    rdmol = Chem.MolFromSmiles(SMILES, sanitize=False)\n",
    "    for atom in rdmol.GetAtoms():\n",
    "        atom.SetAtomMapNum(atom.GetIdx() + 1)\n",
    "    \n",
    "    mono_mols[name] = rdmol\n",
    "    mono_smarts[name] = Chem.MolToSmarts(rdmol)\n",
    "\n",
    "    display(rdmol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomers = {\n",
    "    'MPD_monovalent' : '[H:1]-[#6:2]1:[#6:3](-[H:4]):[#6:5](-[#7:6](-*)-[H:8]):[#6:9](-[H:10]):[#6:11](-[#7:12](-[H:13])-[H:14]):[#6:15]:1-[H:16]',\n",
    "    'MPD_bivalent'   : '[H:1]-[#6:2]1:[#6:3](-[H:4]):[#6:5](-[#7:6](-*)-[H:8]):[#6:9](-[H:10]):[#6:11](-[#7:12](-[H:13])-*):[#6:15]:1-[H:16]',\n",
    "    'TMC_monovalent' : '[H:1]-[#6:2]1:[#6:3](-[#6:4](=[#8:5])-*):[#6:8](-[H:9]):[#6:10](-[#6:11](=[#8:12])-[#8:13]-[H:14]):[#6:15](-[H:16]):[#6:17]:1-[#6:18](=[#8:19])-[#8:20]-[H:21]', \n",
    "    'TMC_bivalent'   : '[H:1]-[#6:2]1:[#6:3](-[#6:4](=[#8:5])-*):[#6:8](-[H:9]):[#6:10](-[#6:11](=[#8:12])-*):[#6:15](-[H:16]):[#6:17]:1-[#6:18](=[#8:19])-[#8:20]-[H:21]', \n",
    "    'TMC_trivalent'  : '[H:1]-[#6:2]1:[#6:3](-[#6:4](=[#8:5])-*):[#6:8](-[H:9]):[#6:10](-[#6:11](=[#8:12])-*):[#6:15](-[H:16]):[#6:17]:1-[#6:18](=[#8:19])-*', \n",
    "}\n",
    "\n",
    "json_spec = {\n",
    "    'monomers' : monomers,\n",
    "    'caps' : {name : [] for name in monomers}\n",
    "}\n",
    "\n",
    "pam_mono_path = POLYAM_PATH/'polyamides.json'\n",
    "with pam_mono_path.open('w') as mono_out:\n",
    "    json.dump(json_spec, mono_out, indent=4)\n",
    "\n",
    "for pam_path in POLYAM_PATH.glob('*.pdb'):\n",
    "    ind_mono_path = POLYAM_PATH/f'{pam_path.stem}.json'\n",
    "    with ind_mono_path.open('w') as mono_out:\n",
    "        json.dump(json_spec, mono_out, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loading of polyamides using monomer spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_pdbs = [path for path in POLYAM_PATH.glob('*.pdb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_file = pam_pdbs[1]\n",
    "\n",
    "openff_topology, _, _error = Topology.from_pdb_and_monomer_info(str(pdb_file), pam_mono_path, strict=False, verbose=False)\n",
    "mol = next(openff_topology.molecules)\n",
    "\n",
    "for atom in mol.atoms:\n",
    "    if not atom.metadata['already_matched']:\n",
    "        print(atom.metadata)\n",
    "\n",
    "rdkdraw.set_rddraw_size(500, 3/2)\n",
    "display(mono_mols[pdb_file.stem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6f4b411abbc3e95cc086ad6e81a9cb26e6bd9b323dd491204b8eb280f272f95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
