{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Imports\n",
    "from polymer_utils import general, filetree, extratypes\n",
    "from polymer_utils import charging as polychg\n",
    "from polymer_utils import simulation as polysim\n",
    "from polymer_utils.representation import PolymerDir, PolymerDirManager\n",
    "from polymer_utils.solvents import WATER_TIP3P\n",
    "\n",
    "# Typing and Subclassing\n",
    "from typing import Any, Callable, ClassVar, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# File I/O\n",
    "from pathlib import Path\n",
    "import csv, json, pickle\n",
    "from shutil import copyfile, rmtree\n",
    "\n",
    "# Logging and Shell\n",
    "import subprocess\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "                            \n",
    "# Cheminformatics\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolfiles\n",
    "\n",
    "# Molecular Dynamics\n",
    "from openff.units import unit\n",
    "from openff.interchange import Interchange\n",
    "\n",
    "from openff.toolkit.topology import Topology\n",
    "from openff.toolkit.topology.molecule import Molecule, Atom\n",
    "from openff.toolkit.typing.engines.smirnoff import ForceField\n",
    "\n",
    "from openff.toolkit.utils.exceptions import ConformerGenerationError\n",
    "from openff.toolkit.utils.toolkits import RDKitToolkitWrapper, OpenEyeToolkitWrapper, AmberToolsToolkitWrapper\n",
    "\n",
    "from openmm import LangevinMiddleIntegrator, Context\n",
    "from openmm.vec3 import Vec3\n",
    "from openmm.app import Simulation, PDBReporter, StateDataReporter\n",
    "\n",
    "from openmm.unit import picosecond, femtosecond, nanosecond # time\n",
    "from openmm.unit import nanometer, angstrom # length\n",
    "from openmm.unit import Unit, kelvin # misc\n",
    "\n",
    "# Static Paths\n",
    "CORE_PATH = Path('Core')\n",
    "POLY_PATH = Path('Polymers')\n",
    "TEST_PATH = Path('Polymers_test')\n",
    "COMPAT_PDB_PATH = Path('compatible_pdbs')\n",
    "\n",
    "POLY_PDB_PATH = COMPAT_PDB_PATH/'simple_polymers'\n",
    "SOLVENTS_PATH = CORE_PATH/'solvents'\n",
    "POLYMER_SOLV_TEMPLATE = CORE_PATH/'inp_templates'/'solv_polymer_template_box.inp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and configuring available polymers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging config\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "LOG_FORMATTER = logging.Formatter('%(asctime)s.%(msecs)03d [%(levelname)s:%(processName)s:line %(lineno)d] - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "      \n",
    "def setup_logger(log_name : str, outpath : Path, writemode='w', formatter : logging.Formatter=None):\n",
    "    '''Boilerplate for creating a new Logger for process output'''\n",
    "    log_path = outpath/f'{log_name}.log'\n",
    "    log_path.touch()\n",
    "\n",
    "    logger = logging.getLogger(log_name) # call is idempotent with same logger namename\n",
    "    if len(logger.handlers) < 1: # prevent duplicate logging output when recreating logger\n",
    "    # if not logger.hasHandlers(): # prevent duplicate logging output when recreating logger\n",
    "        file_handler = logging.FileHandler(log_path, mode=writemode)\n",
    "        if formatter is not None:\n",
    "            file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset     = False #True\n",
    "resolvate = False #True\n",
    "recover   = True\n",
    "\n",
    "solvent = WATER_TIP3P\n",
    "solvent.structure_file = CORE_PATH/'solvents'/solvent.name/f'{solvent.name}.pdb'\n",
    "mgr = PolymerDirManager(collection_dir=POLY_PATH)\n",
    "\n",
    "if reset:\n",
    "    mgr.purge(really=True) \n",
    "    mgr.populate_mol_dirs(source_dir=POLY_PDB_PATH)\n",
    "\n",
    "if resolvate:        \n",
    "    for mol_name, mol_dir in mgr.mol_dirs.items():\n",
    "        if mol_dir.info.solvent is None: # only try to solvate systems which don't already have a solvent\n",
    "            print(mol_name)\n",
    "            solv_dir = mol_dir.solvate(template_path=POLYMER_SOLV_TEMPLATE, solvent=solvent, exclusion=1*nanometer)\n",
    "\n",
    "    mgr.update_mol_dirs() # ensure solvated dirs are added to collection\n",
    "\n",
    "if recover:\n",
    "    # When resolvation, ensure leftover charge files from previous solvation sims are reassigned\n",
    "    recovery_attrs = {\n",
    "        'pkl' : 'pickle_file',\n",
    "        'FF'  : 'ff_file'\n",
    "    }\n",
    "\n",
    "    for mol_dir in mgr.mol_dirs_list:\n",
    "        for subdir_name, attr_name in recovery_attrs.items():\n",
    "            try:\n",
    "                subdir = getattr(mol_dir, subdir_name)\n",
    "                existing_file = next(subdir.iterdir()) # raises StopIteration if folder is empty\n",
    "                setattr(mol_dir.info, attr_name, existing_file)\n",
    "                mol_dir.to_file() # ensure info is updated on disc copy\n",
    "\n",
    "                print(mol_dir.info)\n",
    "            except StopIteration:\n",
    "                pass\n",
    "\n",
    "print([i for i in mgr.mol_dirs.keys()], '\\n', mgr.all_completed_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge/Sim loop V1 proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE TARGET MOLECULES AND FORCEFIELD\n",
    "# sample_mols = mols_to_use[:3]\n",
    "sample_mols = ['polyvinylchloride']\n",
    "main_ff_xml = CORE_PATH/'force_fields'/'openff_unconstrained-2.0.0.offxml'\n",
    "\n",
    "# CHARGING PARAMETERS\n",
    "toolkit = 'OpenEye Toolkit'\n",
    "partial_charge_method = 'am1bccelf10'\n",
    "\n",
    "# CHARGING / SIM LOOP BEHAVIOR\n",
    "overwrite_ff_xml   = True\n",
    "overwrite_chg_json = True\n",
    "distrib_mono_charges = True\n",
    "run_sims = True\n",
    "strict = True\n",
    "verbose = False\n",
    "\n",
    "# SIMULATION PARAMETERS \n",
    "temperature = 300 * kelvin\n",
    "friction_coeff = 1/picosecond\n",
    "\n",
    "sim_time = 0.001 * nanosecond #5 * nanosecond \n",
    "timestep = 1 * femtosecond\n",
    "num_samples = 100 #2_000\n",
    "\n",
    "# AUXILIARY PRE-FLIGHT CALCULATIONS\n",
    "sample_dirs = {\n",
    "    mol_name : mgr.mol_dirs.get(mol_name)\n",
    "        for mol_name in sample_mols\n",
    "}\n",
    "action_str = f'Charging{\" & simulation\" if run_sims else \"\"}'\n",
    "\n",
    "num_steps   = round(sim_time / timestep)\n",
    "record_freq = round(num_steps / num_samples)\n",
    "num_mols = len(sample_dirs)\n",
    "print(num_steps, record_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_logger = logging.getLogger(charging.__name__)\n",
    "\n",
    "def create_pickled_cmol(mol_dir : PolymerDir, toolkit : str, partial_charge_method : str, strict : bool=True, verbose : bool=False) -> None:\n",
    "    '''Ensure that a pickled, charged molecule exists for the mol directory - perform charging with method of choice if none exists'''\n",
    "    pickle_path = mol_dir.pkl/f'{mol_dir.mol_name}.pkl'\n",
    "\n",
    "    chg_logger.info(f'Loading topology and molecule via graph match...')\n",
    "    mol = mol_dir.largest_offmol_matched(strict=strict, verbose=verbose, topo_only=True)\n",
    "    chg_logger.info(f'Charging {mol_dir.mol_name} via {toolkit}-{partial_charge_method}...')\n",
    "    cmol = charging.charging.generate_molecule_charges(mol, toolkit=toolkit, partial_charge_method=partial_charge_method) \n",
    "\n",
    "    with pickle_path.open('wb') as pickle_file: # write charged molecule to pickle to avoid constantly redoing AM1\n",
    "        pickle.dump(cmol, pickle_file)\n",
    "\n",
    "    mol_dir.info.pickle_file = pickle_path # ensure change is reflected in directory info\n",
    "    mol_dir.to_file() # record all changes to disc\n",
    "\n",
    "def create_chg_avg_mono(mol_dir : PolymerDir, distrib_mono_charges : bool=True) -> tuple[list[ChargedResidue], AtomIDMap]:\n",
    "    '''Create a charge-averaged monomer file from an existing monomer spec file and a charged OFF Molecule'''\n",
    "    chg_logger.info('Unpickling charged Molecule for charge averaging...')\n",
    "    with mol_dir.info.pickle_file.open('rb') as pickle_file: \n",
    "        cmol = pickle.load(pickle_file) # load AM1-charged molecule from file (must exist by this point in loop)\n",
    "\n",
    "    chg_logger.info(f'Averaging charges over {mol_dir.mol_name} residues...')\n",
    "    avgs, atom_id_mapping = charging.averaging.get_averaged_charges(cmol, monomer_data=mol_dir.monomer_data, distrib_mono_charges=distrib_mono_charges) # average charges over unique residues\n",
    "    mono_chgs = {avgd_res.residue_name : avgd_res.charges for avgd_res in avgs}\n",
    "    \n",
    "    chg_logger.info(f'Writing new charged JSON monomer file...')\n",
    "    mol_dir.create_charged_monomer_file(mono_chgs)\n",
    "\n",
    "    return avgs, atom_id_mapping\n",
    "\n",
    "def create_off_xml(mol_dir : PolymerDir, xml_src : Path) -> tuple[ForceField, list[LibraryChargeHandler]]:\n",
    "    '''Generate an OFF force field with molecule-specific (and solvent specific, if applicable) Library Charges appended'''\n",
    "    ff_path = mol_dir.FF/f'{mol_dir.mol_name}.offxml' # path to output library charges to\n",
    "    chg_logger.info('Writing new force field OFFXML file')\n",
    "    forcefield, lib_chgs = charging.averaging.write_lib_chgs_from_mono_data(mol_dir.monomer_data_charged, xml_src, output_path=ff_path)\n",
    "\n",
    "    if mol_dir.info.solvent is not None:\n",
    "        chg_logger.info('Associated solvent found, merging Library-Charged force field with solvent force field...')\n",
    "        forcefield = ForceField(ff_path, mol_dir.info.solvent.forcefield_file, allow_cosmetic_attributes=True) # use both the polymer-specific xml and the solvent FF xml to make hybrid forcefield\n",
    "        forcefield.to_file(ff_path)\n",
    "\n",
    "    mol_dir.info.ff_file = ff_path # ensure change is reflected in directory info\n",
    "    mol_dir.to_file() # record all changes to disc\n",
    "\n",
    "    return forcefield, lib_chgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN CHARGING / SIM LOOP - Perform charge averaging on all target molecules which don't already have averaged LCs; Load forcefield for those which already do \n",
    "main_logger = logging.getLogger(__name__)\n",
    "loggers = [main_logger, chg_logger]\n",
    "main_log_handler = config_mlf_handler(mgr.log_dir/f'Polymer_battery_{general.timestamp_now()}.log', loggers, writemode='a')\n",
    "\n",
    "main_logger.info(f'Beginning {action_str} loop...\\n')\n",
    "for i, (mol_name, mol_dir) in enumerate(sample_dirs.items()):\n",
    "    # 0) LOAD MOLECULE AND TOPOLOGY, ATTEMPT TO APPLY LIBRARY CHARGES\n",
    "    start_time = datetime.now()\n",
    "    main_logger.info(f'Current molecule: \"{mol_name}\" ({i + 1}/{num_mols})') # +1 converts to more human-readable 1-index for step count\n",
    "    polymer_log_handler = config_mlf_handler(mol_dir.logs/f'{general.timestamp_now()}.log', loggers, writemode='w') # NOTE : order matters, initial main logger call above should not record to local polymer log\n",
    "    if not mol_dir.has_monomer_data:\n",
    "        raise FileExistsError(f'No monomer JSONs found for {mol_name}')\n",
    "    \n",
    "    # 1) ENSURING AN AM1-BCC-ELF10-CHARGED MOLECULE EXISTS (IN PICKLE FORM). WILL RECHARGE IF NONE EXISTS\n",
    "    if (mol_dir.info.pickle_file is None):\n",
    "        main_logger.warning('(1-precheck) Generating new pickled charged OpenFF Molecule...')\n",
    "        try:\n",
    "            create_pickled_cmol(mol_dir, toolkit, partial_charge_method, strict, verbose)\n",
    "        except ConformerGenerationError:\n",
    "            main_logger.error('Could not successfully generate conformers\\n')\n",
    "            continue \n",
    "    main_logger.info('(1) Found pickled charged molecule...')\n",
    "    \n",
    "    # 2) CREATE JSON WITH AVERAGED CHARGES IF ONE DOES NOT ALREADY EXIST\n",
    "    if (mol_dir.info.monomer_file_chgd is None) or overwrite_chg_json: # can only reach this branch if a json is present but isn't identified as charged within the PolymerDir\n",
    "        main_logger.warning('(2-precheck) Generating new charged monomer JSON...')\n",
    "        create_chg_avg_mono(mol_dir, distrib_mono_charges=distrib_mono_charges)\n",
    "    main_logger.info('(2) Found charged monomer JSON...')\n",
    "\n",
    "    # 3) CREATE FORCE FIELD XML WITH MONOMER-BASED LIBRARY CHARGE ENTRIES\n",
    "    if (mol_dir.info.ff_file is None) or overwrite_ff_xml: # can only reach if a charged monomer json already exists\n",
    "        main_logger.warning('(3-precheck) Generating new Force Field XML with Library Charges...')\n",
    "        create_off_xml(mol_dir, xml_src=main_ff_xml)\n",
    "    main_logger.info('(3) Found Force Field file with Library Charges...')\n",
    "\n",
    "    # 4) RUN OpenMM SIMULATION FOR TARGET MOLECULE\n",
    "    if run_sims:\n",
    "        main_logger.info('(4) Preparing simulation...')\n",
    "        output_folder = mol_dir.make_res_dir()\n",
    "        sim_log_handler = config_mlf_handler(output_folder/f'{mol_dir.mol_name} simulation.log', loggers)\n",
    "\n",
    "        main_logger.info('Loading Topology...')\n",
    "        openff_topology = mol_dir.openff_topology_matched(strict=strict, verbose=verbose, topo_only=True)\n",
    "        openff_topology.box_vectors = mol_dir.box_vectors.in_units_of(nanometer) # set box vector to allow for periodic simulation (will be non-periodic if mol_dir box vectors are unset i.e. NoneType)\n",
    "\n",
    "        main_logger.info('Loading charged Molecule...')\n",
    "        with mol_dir.info.pickle_file.open('rb') as pickle_file: \n",
    "            cmol = pickle.load(pickle_file) # load AM1-charged molecule from file (must exist by this point in loop)\n",
    "\n",
    "        main_logger.info('Loading Force Field...')\n",
    "        forcefield = ForceField(mol_dir.info.ff_file, allow_cosmetic_attributes=True)\n",
    "\n",
    "        main_logger.info('Creating Simulation from Interchange...')\n",
    "        interchange = Interchange.from_smirnoff(force_field=forcefield, topology=openff_topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "        integrator  = LangevinMiddleIntegrator(temperature, friction_coeff, timestep)\n",
    "        sim = polysim.create_simulation(interchange, integrator)\n",
    "        \n",
    "        main_logger.info(f'Running {sim_time} OpenMM sim at {temperature} for {num_steps} steps...')\n",
    "        polysim.run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=num_steps, record_freq=record_freq)\n",
    "\n",
    "        mol_dir.to_file() # ensure directory data reflects changes to files\n",
    "        # filetree.startfile(output_folder)\n",
    "        sim_log_handler.remove_from_loggers(*loggers)  \n",
    "    \n",
    "    proc_time = str(datetime.now() - start_time)\n",
    "    main_logger.info(f'Successfully completed actions on {mol_name} in {proc_time}\\n')\n",
    "    clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "    polymer_log_handler.remove_from_loggers(*loggers)  \n",
    "\n",
    "main_logger.info(f'{action_str} loop completed')\n",
    "main_log_handler.remove_from_loggers(*loggers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Sims v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_dirs = mgr.mol_dirs\n",
    "\n",
    "desired_solvents = (WATER_TIP3P,) #,None)\n",
    "hard_polymers = ['vulcanizedrubber', 'polyphenylenesulfone', 'polyethylene'] # pathological or otherwise difficult-to-run polymers that I've encountered\n",
    "hard_polymers_solv = [\n",
    "    f'{unsolv_mol}_solv_{solvent.name}'\n",
    "        for solvent in desired_solvents\n",
    "            for unsolv_mol in hard_polymers\n",
    "]\n",
    "hard_polymers.extend(hard_polymers_solv) # ensure solvated names are also included\n",
    "\n",
    "mols_to_use = [mol_dir.mol_name\n",
    "    for mol_dir in mol_dirs.values()\n",
    "        if (mol_dir.mol_name not in hard_polymers)         # 1) are not manually excluded\n",
    "            and (0 < mol_dir.n_atoms <= 300)               # 2) are loadable (i.e. non-zero size) but are small enough for AM1BCC (150 is speed limit, 300 is error limit)\n",
    "            and (mol_dir.has_monomer_data)                 # 3) have monomer information files\n",
    "            and (mol_dir.info.solvent in desired_solvents) # 4) is solvated in the specified solvents (could be None)\n",
    "]\n",
    "\n",
    "print(mols_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE TARGET MOLECULES AND FORCEFIELD\n",
    "sample_mols = mols_to_use\n",
    "# sample_mols = ['polyvinylchloride_solv_water']\n",
    "main_ff_xml = CORE_PATH/'force_fields'/'openff_unconstrained-2.0.0.offxml'\n",
    "solv_ff_xml = CORE_PATH/'force_fields'/'tip3p.offxml'\n",
    "\n",
    "# SET CHARGING LOOP BEHAVIOR\n",
    "prevent_overwrites = False # to deprecate\n",
    "distrib_mono_charges = True\n",
    "run_sims = True\n",
    "verbose = False\n",
    "\n",
    "# SIMULATION PARAMETERS \n",
    "temperature = 300 * kelvin\n",
    "friction_coeff = 1/picosecond\n",
    "\n",
    "sim_time = 5 * nanosecond \n",
    "timestep = 1 * femtosecond\n",
    "num_samples = 2_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-FLIGHT CHECKS\n",
    "sample_dirs = {\n",
    "    mol_name : mol_dirs.get(mol_name)\n",
    "        for mol_name in sample_mols\n",
    "}\n",
    "\n",
    "num_steps   = round(sim_time / timestep)\n",
    "record_freq = round(num_steps / num_samples)\n",
    "num_mols = len(sample_dirs)\n",
    "print(num_steps, record_freq)\n",
    "\n",
    "main_log_dir = POLY_PATH/'Logs'\n",
    "main_log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "master_logger = setup_logger(f'Polymer_battery_{general.timestamp_now()}', outpath=main_log_dir, formatter=LOG_FORMATTER, writemode='w')\n",
    "master_handler = master_logger.handlers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN CHARGING / SIM LOOP - Perform charge averaging on all target molecules which don't already have averaged LCs; Load forcefield for those which already do \n",
    "for i, (mol_name, mol_dir) in enumerate(sample_dirs.items()):\n",
    "    log_name = mol_name #f'{mol_name}_chg_sim_log' #{general.timestamp_now()}'\n",
    "    logger = setup_logger(log_name, outpath=mol_dir.logs, writemode='a', formatter=LOG_FORMATTER)\n",
    "    logger.addHandler(master_handler) # ensure output is also logged to the master\n",
    "\n",
    "    # DEFINING PATHS, CREATING FOLDERS, AND FETCHING FILES\n",
    "    pdb_path      = mol_dir.info.structure_file\n",
    "    lc_path       = mol_dir.FF/f'new {mol_name} charges.offxml' # path to output library charges to\n",
    "    pickle_path   = mol_dir.pkl/f'{mol_name}.pkl'\n",
    "    output_folder = mol_dir.make_res_dir()\n",
    "\n",
    "    # LOAD MOLECULE AND TOPOLOGY, ATTEMPT TO APPLY LIBRARY CHARGES\n",
    "    logger.info(f'Current molecule: {mol_name} ({i + 1}/{num_mols})') # +1 converts to more human-readable 1-index for step count\n",
    "    json_path = mol_dir.monomer_file_ranked\n",
    "    if json_path is None:\n",
    "        raise FileExistsError(f'No monomer JSONs found for {mol_name}')\n",
    "    \n",
    "    logger.info(f'Using monomer file \"{json_path}\"...')\n",
    "    with json_path.open('r') as json_file:\n",
    "        mono_data = json.load(json_file)\n",
    "\n",
    "    logger.info(f'Loading and matching molecule \"{mol_name}\"...')\n",
    "    openff_topology, _, _error = Topology.from_pdb_and_monomer_info(str(pdb_path), json_path, strict=True, verbose=verbose)\n",
    "    openff_topology.box_vectors = mol_dir.box_vectors.in_units_of(nanometer) # set box vector to allow for periodic simulation (will be non-periodic if mol_dir box vectors are unset i.e. NoneType)\n",
    "    mol = next(openff_topology.molecules) # get the first molecule (assumed to be the polymer of interest)\n",
    "\n",
    "    if prevent_overwrites and lc_path.exists(): # check if library charges have already been generated for this molecule\n",
    "        logger.info('Obtaining partial charges from Library Charge xml...')\n",
    "        forcefield = ForceField(lc_path, solv_ff_xml, allow_cosmetic_attributes=True) # use both the polymer-specific xml and the solvent FF xml when creating the Forcefield\n",
    "        \n",
    "        logger.info('Unpickling charged Molecule...')\n",
    "        with pickle_path.open('rb') as pickle_file: # read cmol from file if already extant\n",
    "            cmol = pickle.load(pickle_file)\n",
    "    else:\n",
    "        # PERFORMING INITIAL AM1-BCC CHARGING, OR UNPICKLING MOLECULE IF THIS HAS ALREADY BEEN DONE\n",
    "        if not pickle_path.exists():\n",
    "            logger.warning('No extant pickled charged Molecule found, performing charging...')\n",
    "            try:\n",
    "                cmol = polychg.generate_molecule_charges(mol, partial_charge_method='am1bccelf10') # perform AM1BCC\n",
    "            except ConformerGenerationError:\n",
    "                logger.warning('Could not successfully generate conformers')\n",
    "                continue \n",
    "\n",
    "            with pickle_path.open('wb') as pickle_file: # write charged molecule to pickle to avoid constantly redoing AM1\n",
    "                pickle.dump(cmol, pickle_file)\n",
    "            mol_dir.info.pickle_file = pickle_path\n",
    "        \n",
    "        logger.info('Unpickling charged Molecule...')\n",
    "        with pickle_path.open('rb') as pickle_file: # read cmol from file if already extant\n",
    "            cmol = pickle.load(pickle_file)\n",
    "\n",
    "        # CHARGE AVERAGING\n",
    "        logger.info(f'Averaging charges over {mol_name} residues...')\n",
    "        avgs, atom_id_mapping = polychg.get_averaged_charges(cmol, monomer_data=mono_data, distrib_mono_charges=distrib_mono_charges) # average charges over unique residues\n",
    "\n",
    "        logger.warning('Library Charge file not found OR overwrite allowed, writing new Library Charge xml...')\n",
    "        forcefield, lib_chgs = polychg.write_new_library_charges(avgs, main_ff_xml, output_path=lc_path)\n",
    "        mol_dir.info.ff_file = lc_path\n",
    "        \n",
    "        # CREATE JSON WITH AVERAGED CHARGES IF ONE DOES NOT ALREADY EXIST\n",
    "        if mol_dir.info.monomer_file_chgd is None:\n",
    "            logger.info('Writing new monomer JSON with charge data...')\n",
    "\n",
    "            mono_chgs = {avgd_res.residue_name : avgd_res.charges for avgd_res in avgs}\n",
    "            if mol_dir.info.solvent is not None:\n",
    "                mono_data['charges'] = {**mono_chgs, **mol_dir.info.solvent.monomer_json_data['charges']} # ensure solvent \"monomer\" charges are also recorded\n",
    "\n",
    "            chgd_json_path = json_path.with_name(f'{json_path.stem}_charged.json')\n",
    "            chgd_json_path.touch()\n",
    "            with chgd_json_path.open('w') as new_json:\n",
    "                json.dump(mono_data, new_json, indent=4)\n",
    "            mol_dir.info.monomer_file_chgd = chgd_json_path\n",
    "\n",
    "    # RUN OpenMM SIMULATION FOR TARGET MOLECULE\n",
    "    if run_sims:\n",
    "        logger.info(f'Running {sim_time} OpenMM sim at {temperature} for {num_steps} steps...')\n",
    "\n",
    "        forcefield = ForceField(lc_path, solv_ff_xml, allow_cosmetic_attributes=True)\n",
    "        interchange = Interchange.from_smirnoff(force_field=forcefield, topology=openff_topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "        integrator  = LangevinMiddleIntegrator(temperature, friction_coeff, timestep)\n",
    "        \n",
    "        sim = polysim.create_simulation(interchange, integrator)\n",
    "        polysim.run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=num_steps, record_freq=record_freq)\n",
    "    \n",
    "    mol_dir.to_file() # ensure directory data reflects changes to files\n",
    "    # filetree.startfile(output_folder)\n",
    "    clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "    logger.info(f'Successfully completed actions on {mol_name}\\n')\n",
    "    logger.removeHandler(master_handler) # free up master log handler - prevents bleed-over between multiple sim sessions\n",
    "\n",
    "master_logger.info(f'Charging{\" & simulation\" if run_sims else \"\"} loop completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.root.manager.loggerDict # use this to link SMIRNOFF and others to logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_sims = lambda : set(sample_mols) - set(mgr.all_completed_sims(mol_dirs).keys())\n",
    "failed_sims()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking molecule size discrepancies between RDKit, OpenFF Molecule.from_file, and OpenFF Molecule.from_pdb_and_monomer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_sizes = {}\n",
    "\n",
    "# RDKIT sizes\n",
    "sizes = {}\n",
    "for path in POLY_PDB_PATH.glob('**/*.pdb'):\n",
    "    try:\n",
    "        sizes[path.stem] = Chem.MolFromPDBFile(str(path), removeHs=False).GetNumAtoms()\n",
    "    except Exception as e:\n",
    "        print(path.name, e)\n",
    "sizes = general.sort_dict_by_values(sizes)\n",
    "mol_sizes['rdkit'] = sizes\n",
    "\n",
    "# OpenFF sizes\n",
    "sizes2 = {}\n",
    "for path in POLY_PDB_PATH.glob('**/*.pdb'):\n",
    "    try:\n",
    "        sizes2[path.stem] = len(Molecule.from_file(path, toolkit_registry=polychg.TOOLKITS['openeye']()).atoms)\n",
    "    except Exception as e:\n",
    "        print(path.stem, ' failed', e)\n",
    "mol_sizes['openff_file'] = sizes2\n",
    "\n",
    "# Pre-computed sizes from old workflow\n",
    "q = Path('Available Polymers.json')\n",
    "with q.open('r') as file:\n",
    "    mol_sizes['openff_pdb_mono'] = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {mol_name for sizes in mol_sizes.values() for mol_name in sizes}\n",
    "header = {'Species' : list(mol_sizes.keys())}\n",
    "compare = {\n",
    "    mol_name : [sizes.get(mol_name) for sizes in mol_sizes.values()]\n",
    "        for mol_name in names\n",
    "}\n",
    "compare = {k : compare[k] for k in sorted(compare)}\n",
    "compare = {**header, **compare}\n",
    "\n",
    "\n",
    "for species, sizes in compare.items():\n",
    "    if len(set(sizes)) > 1:\n",
    "        print(species, sizes)\n",
    "\n",
    "compare        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking which force field XMLs are non-unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_dir = CORE_PATH/'force_fields'\n",
    "\n",
    "dat = []\n",
    "for ff_xml in ff_dir.iterdir():\n",
    "    with ff_xml.open('r') as file:\n",
    "        info = file.read()\n",
    "        # if info in dat:\n",
    "        print(ff_xml.name)\n",
    "        # else:\n",
    "        dat.append(info)\n",
    "\n",
    "len(set(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([\n",
    "    [i == j\n",
    "        for i in dat]\n",
    "            for j in dat\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6f4b411abbc3e95cc086ad6e81a9cb26e6bd9b323dd491204b8eb280f272f95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
