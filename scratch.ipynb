{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timber/miniconda3/envs/openff-dev-updated/lib/python3.10/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/timber/miniconda3/envs/openff-dev-updated/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/timber/miniconda3/envs/openff-dev-updated/lib/python3.10/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/timber/miniconda3/envs/openff-dev-updated/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "Warning on use of the timeseries module: If the inherent timescales of the system are long compared to those being analyzed, this statistical inefficiency may be an underestimate.  The estimate presumes the use of many statistically independent samples.  Tests should be performed to assess whether this condition is satisfied.   Be cautious in the interpretation of the data.\n",
      "WARNING:root:Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    }
   ],
   "source": [
    "# Custom Imports\n",
    "import polysaccharide as ps\n",
    "from polysaccharide import analysis, extratypes, filetree, general, logutils, molutils\n",
    "from polysaccharide import polymer\n",
    "\n",
    "from polysaccharide.charging.residues import ChargedResidue\n",
    "from polysaccharide.charging.application import CHARGER_REGISTRY, ChargingParameters\n",
    "\n",
    "from polysaccharide import LOGGERS_MASTER\n",
    "from polysaccharide.logutils import ProcessLogHandler\n",
    "\n",
    "from polysaccharide.molutils.rdmol import rdkdraw\n",
    "\n",
    "from polysaccharide.polymer.representation import Polymer\n",
    "from polysaccharide.polymer.management import PolymerManager\n",
    "from polysaccharide.polymer.filtering import has_sims, is_solvated, is_unsolvated, is_charged\n",
    "from polysaccharide.polymer import building, monomer\n",
    "\n",
    "from polysaccharide.solvation.solvents import WATER_TIP3P\n",
    "from polysaccharide.analysis import trajectory, statistics\n",
    "from polysaccharide.simulation.records import SimulationPaths, SimulationParameters\n",
    "from polysaccharide.graphics import plotutils\n",
    "\n",
    "# Generic Imports\n",
    "import re\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Numeric imports\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Typing and Subclassing\n",
    "from typing import Any, Callable, ClassVar, Iterable, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "from openmm.unit import Unit, Quantity\n",
    "\n",
    "# File I/O\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import csv, json, pickle\n",
    "from shutil import copyfile, rmtree\n",
    "import importlib.resources as impres\n",
    "\n",
    "# Logging and Shell\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=logutils.LOG_FORMATTER._fmt,\n",
    "    datefmt=logutils.LOG_FORMATTER.datefmt,\n",
    "    force=True\n",
    ")\n",
    "                            \n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolfiles\n",
    "\n",
    "# Molecular Dynamics\n",
    "from openff.interchange import Interchange\n",
    "from openff.toolkit import ForceField\n",
    "from openff.toolkit.topology import Topology\n",
    "from openff.toolkit.topology.molecule import Molecule, Atom\n",
    "from openff.toolkit.typing.engines.smirnoff.parameters import LibraryChargeHandler\n",
    "\n",
    "from openff.units import unit\n",
    "from openmm.unit import picosecond, femtosecond, nanosecond # time\n",
    "from openmm.unit import nanometer, angstrom # length\n",
    "from openmm.unit import kelvin, atmosphere # misc\n",
    "\n",
    "# polymer resource management\n",
    "import importlib_resources as impres\n",
    "from polysaccharide import resources\n",
    "from polysaccharide.resources import AVAIL_RESOURCES\n",
    "\n",
    "RESOURCE_PATH = resources.RESOURCE_PATH\n",
    "SIM_PARAM_PATH = impres.files(resources.sim_templates)\n",
    "CHG_PARAM_PATH = impres.files(resources.chg_templates)\n",
    "INP_PARAM_PATH = impres.files(resources.inp_templates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing replicates for Polymers paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Paths and PolymerManagers\n",
    "data_dir = Path('data_for_paper')\n",
    "\n",
    "colina_dir = data_dir / 'colina_data'\n",
    "\n",
    "openff_dir = data_dir / 'openff_data'\n",
    "openff_dir.mkdir(exist_ok=True)\n",
    "\n",
    "combined_dir = data_dir / 'combined_data'\n",
    "combined_dir.mkdir(exist_ok=True)\n",
    "\n",
    "COLL_PATH = Path('Collections')\n",
    "\n",
    "conf_mgr = PolymerManager(COLL_PATH / 'water_soluble_polymers_confs')\n",
    "equil_mgr = PolymerManager(COLL_PATH / 'water_soluble_polymers_equil')\n",
    "# targ_mgr = conf_mgr\n",
    "targ_mgr = equil_mgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting high-dimensional data \"cube\" of observable averages for all replicates\n",
    "full_data = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))\n",
    "for mol_name, sim_dirs_list in targ_mgr.all_completed_sims.items():\n",
    "    polymer = targ_mgr.polymers[mol_name]\n",
    "    for sim_dir in sim_dirs_list:\n",
    "        sim_paths, sim_params = polymer.load_sim_paths_and_params(sim_dir)\n",
    "\n",
    "        time_data = pd.read_csv(sim_paths.time_data)\n",
    "        x_data, y_data = trajectory.props_to_plot_data(time_data)\n",
    "        for prop_name, time_series in y_data.items():\n",
    "            full_data[polymer.base_mol_name][sim_params.charge_method][prop_name].append(time_series.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing means and uncertainties and collating into dataframes \n",
    "dframe_fns = {\n",
    "    'obs' : np.mean,\n",
    "    'std' : np.std\n",
    "}\n",
    "\n",
    "for mol_name, mol_dict in full_data.items():\n",
    "    for outname, dframe_fn in dframe_fns.items():\n",
    "        dframe = pd.concat([\n",
    "            pd.DataFrame.from_dict(\n",
    "                {prop_name : dframe_fn(prop_data) for prop_name, prop_data in prop_dict.items()},\n",
    "                orient='index',\n",
    "                columns=[f'Sage 2.0.0 - {chg_method}']\n",
    "            ) \n",
    "            for chg_method, prop_dict in mol_dict.items()\n",
    "        ], axis=1)\n",
    "\n",
    "        dframe.to_csv(openff_dir / f'{mol_name}_{outname}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging new dataframes with data from Colina paper\n",
    "for ref_data_dir in colina_dir.iterdir():\n",
    "    filename = ref_data_dir.name\n",
    "\n",
    "    new_data = pd.read_csv(openff_dir / filename, index_col=0)\n",
    "    ref_data = pd.read_csv(ref_data_dir, index_col=0)\n",
    "    data = pd.concat([new_data, ref_data], axis=1)\n",
    "\n",
    "    data.to_csv(combined_dir / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m mol_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpeg_modified\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m exps_path \u001b[39m=\u001b[39m data_dir \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmol_name\u001b[39m}\u001b[39;00m\u001b[39m_exp.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      4\u001b[0m stds_path \u001b[39m=\u001b[39m data_dir \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmol_name\u001b[39m}\u001b[39;00m\u001b[39m_std.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      6\u001b[0m exps \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(exps_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "mol_name = 'peg_modified'\n",
    "\n",
    "exps_path = data_dir / f'{mol_name}_exp.csv'\n",
    "stds_path = data_dir / f'{mol_name}_std.csv'\n",
    "\n",
    "exps = pd.read_csv(exps_path)\n",
    "stds = pd.read_csv(stds_path)\n",
    "\n",
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(openff_dir / filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting replicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_dict = data_agg['ABE10_averaged']\n",
    "# chg_dict = data_agg['Espaloma_AM1BCC']\n",
    "\n",
    "fig, ax = plotutils.presize_subplots(nrows=1, ncols=len(chg_dict))\n",
    "for axis, (mol_name, prop_dict) in zip(ax.flatten(), chg_dict.items()):\n",
    "    x_pos = np.arange(len(prop_dict))\n",
    "    means, stds = [], []\n",
    "\n",
    "    for prop_name, prop_data in prop_dict.items():\n",
    "        means.append(np.mean(prop_data))\n",
    "        stds.append(np.std(prop_data))\n",
    "\n",
    "    axis.set_title(f'{mol_name} Shape Properties')\n",
    "    axis.bar(x_pos, means, yerr=stds)\n",
    "    axis.set_xticks(x_pos)\n",
    "    axis.set_xticklabels(prop_dict.keys(), rotation=-45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_method = 'Espaloma_AM1BCC'\n",
    "pd.DataFrame(data_agg[chg_method]['paam_modified'].items(), columns=['', chg_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdir = mgr.polymers['polyvinylchloride']\n",
    "spath, sparam = pdir.load_sim_paths_and_params()\n",
    "df = pd.read_csv(spath.state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr_equil = PolymerManager(COLL_PATH / 'water_soluble_polymers_equil')\n",
    "for mol_name, polymer in mgr_equil.filtered_by(is_solvated).items():\n",
    "    print(mol_name, len(polymer.completed_sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_dframe = pd.read_csv(sim_paths.spatial_data)\n",
    "radii, rdfs = analysis.trajectory.rdfs_to_plot_data(rdf_dframe)\n",
    "fig, ax = plotutils.plot_df_props(radii, rdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_dframe = pd.read_csv(sim_paths.time_data)\n",
    "times, props = analysis.trajectory.props_to_plot_data(prop_dframe)\n",
    "fig, ax = plotutils.plot_df_props(times, props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr_confs = PolymerManager(COLL_PATH / 'water_soluble_polymers_confs')\n",
    "mol_name = 'paam_modified_conf_1_solv_water'\n",
    "\n",
    "pdir = mgr_confs.polymers[mol_name]\n",
    "sim_dir = mgr_confs.all_completed_sims[mol_name][0]\n",
    "sim_paths, sim_params = pdir.load_sim_paths_and_params(sim_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing generic ideas and developing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Imports\n",
    "import re\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Numeric imports\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Typing and Subclassing\n",
    "from typing import Any, Callable, ClassVar, Iterable, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "\n",
    "# File I/O\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import csv, json, pickle\n",
    "from shutil import copyfile, rmtree\n",
    "import importlib.resources as impres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing fields from XML (useful for annoying barostat in OpenMM states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "for sim_dir, sim_paths_file in pdir.simulation_paths.items():\n",
    "    sim_paths = SimulationPaths.from_file(sim_paths_file)\n",
    "    chk = sim_paths.checkpoint\n",
    "    if chk.suffix == '.xml':\n",
    "        tree = ET.parse(sim_paths.checkpoint)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        par = next(root.iter('Parameters'))\n",
    "        par.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dynamic checkpoint file updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class Test:\n",
    "    def __init__(self, val : int, checkpoint : Path) -> None:\n",
    "        self.val = val\n",
    "        self.checkpoint_path = checkpoint\n",
    "\n",
    "    def to_file(self):\n",
    "        if hasattr(self, 'checkpoint_path'):\n",
    "            with self.checkpoint_path.open('wb') as file:\n",
    "                pickle.dump(self, file)\n",
    "\n",
    "    def __setattr__(self, __name: str, __value: Any) -> None:\n",
    "        super().__setattr__(__name, __value)\n",
    "        self.to_file()\n",
    "        print(__name, __value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('test.pkl')\n",
    "p.touch()\n",
    "\n",
    "t = Test(5, p)\n",
    "t.other = 'word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with p.open('rb') as file:\n",
    "    v = pickle.load(file)\n",
    "\n",
    "v.__dict__\n",
    "v.foo = 'bar'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with grid size optimization WRT aspect and number of squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, sqrt, floor\n",
    "\n",
    "def size_penalty(N_targ : int, N_real : int) -> float:\n",
    "    return (N_real / N_targ - 1)**2\n",
    "\n",
    "def aspect_penalty(a_targ : float, a_real : float) -> float:\n",
    "    # return (a_real / a_targ - 1)**2\n",
    "    return 1 - min(a_targ / a_real, a_real / a_targ)\n",
    "\n",
    "def dims(N : int, a : float=1/1, w1=1, w2=1) -> tuple[int, int]:\n",
    "    '''Given a particular number of cells and an aspect ratio, yields the smallest 2x2 grid dimensions which accomodate at least N grid squares whose aspect ratio is closest to the '''\n",
    "    return min( \n",
    "        ((r, ceil(N / r))\n",
    "            for r in range(1, N + 1)\n",
    "        ),\n",
    "        key=lambda dims : w1*size_penalty(N, dims[0]*dims[1]) + w2*aspect_penalty(a, dims[0]/dims[1])\n",
    "    )\n",
    "\n",
    "a = 2/1\n",
    "for N in range(1, 20):\n",
    "    nrows, ncols = dims(N, a)\n",
    "    fig, ax = plotutils.presize_subplots(nrows=nrows, ncols=ncols, scale=1)\n",
    "    fig.suptitle(f'N = {N}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
